<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.13.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>K-Nearest Neighbor Classification in Scikit Learn - Blog</title>
<meta name="description" content="K-Nearest Neighbor (k-NN) presents a a simple straightforward instance-basedlearning. Often, a simple strategy produces a good result as well as acting asbaseline performance.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Blog">
<meta property="og:title" content="K-Nearest Neighbor Classification in Scikit Learn">
<meta property="og:url" content="https://erickguan.me/2017/k-nearest-neighbour-in-scikit-learn">


  <meta property="og:description" content="K-Nearest Neighbor (k-NN) presents a a simple straightforward instance-basedlearning. Often, a simple strategy produces a good result as well as acting asbaseline performance.">





  <meta name="twitter:site" content="@erickguan">
  <meta name="twitter:title" content="K-Nearest Neighbor Classification in Scikit Learn">
  <meta name="twitter:description" content="K-Nearest Neighbor (k-NN) presents a a simple straightforward instance-basedlearning. Often, a simple strategy produces a good result as well as acting asbaseline performance.">
  <meta name="twitter:url" content="https://erickguan.me/2017/k-nearest-neighbour-in-scikit-learn">

  
    <meta name="twitter:card" content="summary">
    
  

  



  <meta property="article:published_time" content="2017-11-02T00:00:00+01:00">





  

  


<link rel="canonical" href="https://erickguan.me/2017/k-nearest-neighbour-in-scikit-learn">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Erick Guan",
      "url": "https://erickguan.me",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#da532c">
<meta name="apple-mobile-web-app-title" content="Erick Guan">
<meta name="application-name" content="Erick Guan">
<meta name="theme-color" content="#ffffff">

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Blog</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about" >About</a>
            </li><li class="masthead__menu-item">
              <a href="https://lifelimited.company" >中文</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  

  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="K-Nearest Neighbor Classification in Scikit Learn">
    <meta itemprop="description" content="K-Nearest Neighbor (k-NN) presents a a simple straightforward instance-basedlearning. Often, a simple strategy produces a good result as well as acting asbaseline performance.">
    <meta itemprop="datePublished" content="November 02, 2017">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">K-Nearest Neighbor Classification in Scikit Learn
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>K-Nearest Neighbor (k-NN) presents a a simple straightforward instance-based
learning. Often, a simple strategy produces a good result as well as acting as
baseline performance.</p>

<p>This article doesn’t deliver new knowledge but an interpretation and bridge to
others’ work. The reader need to understand the very basic of Machine Learning.
Especially, code is done with <code class="highlighter-rouge">scikit-learn</code>.</p>

<p>In particular, KNN can be used in classification. The training data is vector
in a multidimensional space with a class label. <code class="highlighter-rouge">k</code> is an user-defined constant.
A test sample is classified based on a distance metric with <code class="highlighter-rouge">k</code> nearest samples from
the training data. That distance metric can be Euclidean distance for continuous
variables. As of discrete data, Hamming distance is a good choice.</p>

<p>In Scholarpedia, it was visualized with Voronoi tessellation:</p>

<blockquote>
  <p>The k-nearest-neighbor classifier is commonly based on the Euclidean distance between a test sample and the specified training samples. Let <script type="math/tex">\mathbf{x}_i</script> be an input sample with <script type="math/tex">p</script> features <script type="math/tex">(\mathbf{x}_{i1},\mathbf{x}_{i2},\ldots,\mathbf{x}_{ip})</script>, <script type="math/tex">n</script> be the total number of input samples <script type="math/tex">(i=1,2,\ldots,n)</script> and <script type="math/tex">p</script> the total number of features <script type="math/tex">(j=1,2,\ldots,p)</script>. The Euclidean distance between sample <script type="math/tex">\mathbf{x}_i</script> and <script type="math/tex">\mathbf{x}_l (l=1,2,\ldots,n)</script> is defined as</p>

  <p><script type="math/tex">d(\mathbf{x}_i,\mathbf{x}_l)=\sqrt{(x_{i1}−x_{l1})^2+(x_{i2}−x_{l2})^2+\cdots+(x_{ip}−x_{lp})^2}</script>.</p>

  <p><img src="/assets/images/2017/knn-voronoi.png" alt="Voronoi tessellation showing Voronoi cells of 19 samples marked with a &quot;+&quot;. The Voronoi tessellation reflects two characteristics of the example 2-dimensional coordinate system: i) all possible points within a sample's Voronoi cell are the nearest neighboring points for that sample, and ii) for any sample, the nearest sample is determined by the closest Voronoi cell edge." /></p>

  <p>A graphic depiction of the nearest neighbor concept is illustrated in the Voronoi tessellation (Voronoi, 1907) shown in Figure. The tessellation shows 19 samples marked with a “+”, and the Voronoi cell, R , surrounding each sample. A Voronoi cell encapsulates all neighboring points that are nearest to each sample and is defined as</p>

  <p><script type="math/tex">R_i=\{\mathbf{x}\in\mathbb{R}^p:d(\mathbf{x},\mathbf{x}_i) \leq d(x,x_m),\forall i \neq m\}</script>,</p>

  <p>where <script type="math/tex">R_i</script> is the Voronoi cell for sample <script type="math/tex">\mathbf{x}_i</script>, and <script type="math/tex">x</script> represents all possible points within Voronoi cell <script type="math/tex">R_i</script>. Voronoi tessellations primarily reflect two characteristics of a coordinate system: i) all possible points within a sample’s Voronoi cell are the nearest neighboring points for that sample, and ii) for any sample, the nearest sample is determined by the closest Voronoi cell edge. Using the latter characteristic, the k-nearest-neighbor classification rule is to assign to a test sample the majority category label of its k nearest training samples. In practice, k is usually chosen to be odd, so as to avoid ties. The k = 1 rule is generally called the nearest-neighbor classification rule.</p>
</blockquote>

<p>This is a great description of understanding. However I found out it’s misleading
as visualization emphasizes too much on Voronoi instead of KNN itself.</p>

<h2 id="how-it-works">How it works</h2>

<p>It all comes out with the code. As in <code class="highlighter-rouge">scikit-learn</code>, the <code class="highlighter-rouge">neighbors.KNeighborsClassifier(n_neighbors, algorithm='brute')</code> implements the most simple way to use KNN. The class comprises of 4 mixins:</p>

<ul>
  <li><code class="highlighter-rouge">SupervisedIntegerMixin</code>: a helper checks parameters and invoke real function.</li>
  <li><code class="highlighter-rouge">ClassifierMixin</code>: also a helper</li>
  <li><code class="highlighter-rouge">NeighborsBase</code>: this mixin choose the optimal algorithm for efficient computing</li>
  <li><code class="highlighter-rouge">KNeighborsMixin</code>: brute method is implemented here.</li>
</ul>

<p>We only have to see how the brute with euclidean distance works to understand it.</p>

<p><code class="highlighter-rouge">X</code> is the input here. <code class="highlighter-rouge">self._fit_X</code> is training data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_samples</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="n">sample_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">]</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_X</span><span class="p">,</span> <span class="s">'euclidean'</span><span class="p">)</span>
<span class="c"># here X is compared with all training samples.</span>
<span class="c"># dist is like a matrix of distance from X to training samples.</span>
<span class="c"># Example: `array([[1, 3, 2, 4]])`, 1 sample with 4 training data.</span>

<span class="n">neigh_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">n_neighbors</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c"># sort until `n_neighbors - 1`. When return, on the left side</span>
<span class="c"># it should be smaller than this data point</span>
<span class="n">neigh_ind</span> <span class="o">=</span> <span class="n">neigh_ind</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_neighbors</span><span class="p">]</span>
<span class="c"># argpartition doesn't guarantee sorted order, so we sort again</span>
<span class="n">neigh_ind</span> <span class="o">=</span> <span class="n">neigh_ind</span><span class="p">[</span>
    <span class="n">sample_range</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="n">sample_range</span><span class="p">,</span> <span class="n">neigh_ind</span><span class="p">])]</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="n">sample_range</span><span class="p">,</span> <span class="n">neigh_ind</span><span class="p">]),</span> <span class="n">neigh_ind</span>
</code></pre></div></div>

<p>Staring from <code class="highlighter-rouge">neigh_ind</code> are some lines only used to sort result.
At last, a distance result and the order of distance to training
data is returned.</p>

<p>If you ever tried <a href="http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification">the sample code</a>, you would notice the
choice of <code class="highlighter-rouge">k</code> affects the result a lot upon iris dataset.</p>

<p>Plus, the weight metric and <code class="highlighter-rouge">RadiusNeighborsClassifier</code> is a
further enhancement.</p>

<h2 id="conclusion">Conclusion</h2>

<p>KNN is a really simple nearest neighbor classification or
regression tool. It’s nothing fancy but with weight and algorithm
you can tweak.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#artificial-intelligence" class="page__taxonomy-item" rel="tag">Artificial Intelligence</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#pattern-recognition" class="page__taxonomy-item" rel="tag">Pattern Recognition</a>
    
    </span>
  </p>




        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2017-11-02T00:00:00+01:00">November 02, 2017</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?via=erickguan&text=K-Nearest+Neighbor+Classification+in+Scikit+Learn%20https%3A%2F%2Ferickguan.me%2F2017%2Fk-nearest-neighbour-in-scikit-learn" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ferickguan.me%2F2017%2Fk-nearest-neighbour-in-scikit-learn" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=https%3A%2F%2Ferickguan.me%2F2017%2Fk-nearest-neighbour-in-scikit-learn" class="btn btn--google-plus" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Google Plus"><i class="fab fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Ferickguan.me%2F2017%2Fk-nearest-neighbour-in-scikit-learn" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/2017/the-surprise-number-in-javascript" class="pagination--pager" title="The Surprising Number in JavaScript
">Previous</a>
    
    
      <a href="/2018/python-iterator" class="pagination--pager" title="Digging in Python iterator and enumerate
">Next</a>
    
  </nav>

    </div>

    
      <div class="page__comments">
  
  
      <h4 class="page__comments-title">Leave a Comment</h4>
      <section id="disqus_thread"></section>
    
</div>
    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/2018/erik-eastman-256489-unsplash-200.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2018/python-iterator" rel="permalink">Digging in Python iterator and enumerate
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">When a PyTorch DataLoader repeat its data? Why it’s so magical and impossible to see in its code. It is implemented as an iterator in Python. Pythonic but im...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/teaser.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2017/the-surprise-number-in-javascript" rel="permalink">The Surprising Number in JavaScript
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">Did you know you can not have a number larger than  in JavaScript?

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/teaser.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2017/copy-and-paste-bookmarklet" rel="permalink">Copy and Paste Bookmarklet
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">Inspired by DontFuckWithPaste.

</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src=
          
            "/assets/images/teaser.jpg"
          
          alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2017/bridging-icu-with-ruby" rel="permalink">Bridging ICU with Ruby
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">Chinese Discourse users have more complains to the text problems. A community
software induce users to read and write which certainly deals with texts.
Numer...</p>
  </article>
</div>
        
      </div>
    </div>
  
  
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 Erick Guan. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"></script>







  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-36993160-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-36993160-8', { 'anonymize_ip': false});
</script>






    
  <script>
    var disqus_config = function () {
      this.page.url = "https://erickguan.me/2017/k-nearest-neighbour-in-scikit-learn";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/2017/k-nearest-neighbour-in-scikit-learn"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://fftenacity.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  



  </body>
</html>